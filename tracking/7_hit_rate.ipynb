{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from utils.data import load_tc_data\n",
    "from utils.plot import make_cmap\n",
    "import cftime as cf\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from netCDF4 import Dataset\n",
    "from numpy import inf\n",
    "# from utils.evaluation import find_landfalling_tcs,tc_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_cmap,precip_norm = make_cmap()\n",
    "levels = [10, 15, 20, 25, 30, 40, 50,75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open storm dataset\n",
    "tc_dir = '/user/home/al18709/work/event_sets/wgan_scalar/'\n",
    "tc_dir = '/user/home/al18709/work/event_sets/wgan_modular/'\n",
    "storm_filename = 'validation_mraw_2006237N13298.nc'\n",
    "storm_filename2 = 'validation_1and2_2006237N13298.nc'\n",
    "storm = xr.open_dataset(tc_dir + storm_filename)\n",
    "storm_scores = np.load(tc_dir + 'validation_mraw_critic_2006237N13298.npy')\n",
    "\n",
    "storm2 = xr.open_dataset(tc_dir + storm_filename2)\n",
    "storm_scores2 = np.load(tc_dir + 'validation_1and2_critic_2006237N13298.npy')\n",
    "\n",
    "tc_dir_truth = '/user/home/al18709/work/event_sets/truth/'\n",
    "storm_truth = xr.open_dataset(tc_dir_truth + 'validation_2006237N13298.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial variables\n",
    "precip_cmap,precip_norm = make_cmap()\n",
    "\n",
    "lats = storm.storm_lats[0,:,:]\n",
    "lons = storm.storm_lons[0,:,:]\n",
    "\n",
    "levels = [10, 15, 20, 25, 30, 40, 50,75, 100]\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\")\n",
    "vmin=0\n",
    "vmax=100\n",
    "\n",
    "print(lats.shape)\n",
    "print(lons.shape)\n",
    "\n",
    "\n",
    "ntime,_,_,_ = storm.precipitation.shape\n",
    "rain = storm.precipitation[0,:,:,0]\n",
    "rain_truth = storm_truth.precipitation[0,:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find storm extent\n",
    "fp = '/bp1/geog-tropical/data/Obs/MSWEP/3hourly_invertlat/2000342.00.nc'\n",
    "d = Dataset(fp, 'r')\n",
    "lat = d.variables['lat'][:] #lat\n",
    "lon = d.variables['lon'][:] #lon\n",
    "lat_lower_bound = (np.abs(lat-np.min(storm.storm_lats))).argmin()\n",
    "lat_upper_bound = (np.abs(lat-np.max(storm.storm_lats))).argmin()\n",
    "lon_lower_bound = (np.abs(lon-np.min(storm.storm_lons))).argmin()\n",
    "lon_upper_bound = (np.abs(lon-np.max(storm.storm_lons))).argmin()\n",
    "\n",
    "lats = lat[lat_lower_bound:lat_upper_bound+2]\n",
    "lons = lon[lon_lower_bound:lon_upper_bound+2]\n",
    "grid_x, grid_y = np.meshgrid(lons,lats)\n",
    "print(grid_x.shape)\n",
    "print(grid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superimpose rain onto bigger grid\n",
    "grid_rain = np.zeros((ntime,grid_x.shape[0],grid_y.shape[1],20))\n",
    "grid_rain2 = np.zeros((ntime,grid_x.shape[0],grid_y.shape[1],20))\n",
    "grid_rain_truth = np.zeros((ntime,grid_x.shape[0],grid_y.shape[1]))\n",
    "\n",
    "for t in range(ntime):\n",
    "\n",
    "\tstorm_lons = storm.storm_lons[t,:,:]\n",
    "\tstorm_lats = storm.storm_lats[t,:,:]\n",
    "\t\n",
    "\tstorm_rain_truth = storm_truth.precipitation[t,:,:,0]\n",
    "\n",
    "\tMlon = storm_lons[-1,-1]\n",
    "\tmlon = storm_lons[0,0]\n",
    "\tMlat = storm_lats[-1,-1]\n",
    "\tmlat = storm_lats[0,0]\n",
    "\tXspan = np.where((grid_x <= Mlon) & (grid_x >= mlon))[1][[0, -1]]\n",
    "\tYspan = np.where((grid_y <= Mlat) & (grid_y >= mlat))[0][[0, -1]]\n",
    "\n",
    "\t# Create a selection\n",
    "\tsel = [slice(Xspan[0], Xspan[1] + 1), slice(Yspan[0], Yspan[1] + 1)]\n",
    "\t# sel = [slice(Xspan[0] - 1, Xspan[1]), slice(Yspan[0] - 1, Yspan[1])]\n",
    "\t# sel = [slice(Yspan[0] -1, Yspan[1] + 1), slice(Xspan[0]-1, Xspan[1] + 1)]\n",
    "\n",
    "\t# grid_rain[t,sel[0],sel[1]] = storm_rain\n",
    "\tfor i in range(20):\n",
    "\t\tstorm_rain = storm.precipitation[t,:,:,i]\n",
    "\t\tgrid_rain[t,sel[1],sel[0],i] = storm_rain\n",
    "\t\tstorm_rain2 = storm2.precipitation[t,:,:,i]\n",
    "\t\tgrid_rain2[t,sel[1],sel[0],i] = storm_rain2\n",
    "\tgrid_rain_truth[t,sel[1],sel[0]] = storm_rain_truth\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_storm_rain = np.sum(grid_rain[:,:,:,0],axis=0)\n",
    "total_storm_rain2 = np.sum(grid_rain2[:,:,:,0],axis=0)\n",
    "total_storm_rain_truth = np.sum(grid_rain_truth,axis=0)\n",
    "rain_bool = total_storm_rain > 50\n",
    "rain_bool2 = total_storm_rain2 > 50\n",
    "print(np.sum(rain_bool))\n",
    "rain_grid_x2 = grid_x[rain_bool2]\n",
    "\n",
    "rain_bool_truth = total_storm_rain_truth > 50\n",
    "print(np.sum(rain_bool_truth))\n",
    "rain_grid_x_truth = grid_x[rain_bool_truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit = (rain_bool == True) & (rain_bool_truth == True)\n",
    "print(np.sum(hit))\n",
    "miss = (rain_bool == False) & (rain_bool_truth == True)\n",
    "hit_rate = np.sum(hit) / (np.sum(hit) + np.sum(miss))\n",
    "print('Hit rate: ',hit_rate*100)\n",
    "\n",
    "false_alarm = (rain_bool == True) & (rain_bool_truth == False)\n",
    "correct_rejection = (rain_bool == False) & (rain_bool_truth == False)\n",
    "false_alarm_rate = np.sum(false_alarm)/(np.sum(false_alarm) + np.sum(correct_rejection))\n",
    "print('false alarm rate',false_alarm_rate*100)\n",
    "\n",
    "hit2 = (rain_bool2 == True) & (rain_bool_truth == True)\n",
    "print(np.sum(hit))\n",
    "miss2 = (rain_bool2 == False) & (rain_bool_truth == True)\n",
    "hit_rate2 = np.sum(hit2) / (np.sum(hit2) + np.sum(miss2))\n",
    "print('Hit rate2: ',hit_rate2*100)\n",
    "\n",
    "false_alarm2 = (rain_bool2 == True) & (rain_bool_truth == False)\n",
    "correct_rejection2 = (rain_bool2 == False) & (rain_bool_truth == False)\n",
    "false_alarm_rate2 = np.sum(false_alarm2)/(np.sum(false_alarm2) + np.sum(correct_rejection2))\n",
    "print('false alarm rate2',false_alarm_rate2*100)\n",
    "\n",
    "# equitable threat score is:\n",
    "# (hit - random chance) / (the observed rain area exceeding the criterion + model precticted area - hit - random chance)\n",
    "# where R = the observed rain area exceeding the criterion * (model predicted area / entire verification domain)\n",
    "# http://cimss.ssec.wisc.edu/goes/comet/threat.html\n",
    "# ETS = (hits - E) / (hits + misses + false alarms - E)\n",
    "# E = (number of forecast points * number of observed points) / total number of points possible\n",
    "\n",
    "n_forecast_points = np.sum(rain_bool == True)\n",
    "n_observed_points = np.sum(rain_bool_truth == True)\n",
    "total_points_possible = np.sum((rain_bool_truth == True) | (rain_bool_truth == False))\n",
    "E = (n_forecast_points*n_observed_points) / total_points_possible\n",
    "ETS = (np.sum(hit) - E) / (np.sum(hit) + np.sum(miss) + np.sum(false_alarm) - E)\n",
    "print('ETS: ', ETS)\n",
    "\n",
    "\n",
    "n_forecast_points2 = np.sum(rain_bool2 == True)\n",
    "n_observed_points2 = np.sum(rain_bool_truth == True)\n",
    "total_points_possible2 = np.sum((rain_bool_truth == True) | (rain_bool_truth == False))\n",
    "E = (n_forecast_points2*n_observed_points2) / total_points_possible2\n",
    "ETS = (np.sum(hit2) - E) / (np.sum(hit2) + np.sum(miss2) + np.sum(false_alarm2) - E)\n",
    "print('ETS2: ', ETS)\n",
    "# The number of forecasts of the event correct by chance, a r , is determined by assuming that the forecasts are totally independent of the observations, and forecast will match the observation only by chance. This is one form of an unskilled forecast, which can be generated by just guessing what will happen. The ETS has a range of -1/3 to 1, but the minimum value depends on the verification sample climatology. For rare events, the minimum ETS value is near 0, while the absolute minimum is obtained if the event has a climatological frequency of 0.5, and there are no hits. If the score goes below 0 then the chance forecast is preferred to the actual forecast, and the forecast is said to be unskilled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exposure_calc(population, rain,threshold):\n",
    "\t\"\"\" number of people exposed to over 200mm in New York\"\"\"\n",
    "\t# population[rain['precipitation'] < 200] = 0\n",
    "\t# print('max rain',np.max(rain['precipitation'].values))\n",
    "\tprint('max rain',np.max(rain))\n",
    "\t# population = population.where(rain['precipitation'].values > threshold,0)\n",
    "\tpopulation = population.where(rain > threshold,0)\n",
    "\t# exposure = np.nansum(population['Population Density, v4.11 (2000, 2005, 2010, 2015, 2020): 2.5 arc-minutes'].values[2])\n",
    "\tpop = population.population.values\n",
    "\tpop[pop == -inf] = 0\n",
    "\texposure = np.nansum(pop)\n",
    "\treturn exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_rain = np.sum(grid_rain,axis=0)\n",
    "accumulated_rain2 = np.sum(grid_rain2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_file = '/user/home/al18709/work/population/ppp_2020_10km_Aggregated_final.nc'\n",
    "population_count = xr.load_dataset(population_file)\n",
    "print(population_count)\n",
    "data = population_count.population.values * 144\n",
    "pop = population_count * 144\n",
    "\n",
    "\n",
    "pop_lats = population_count.lat\n",
    "pop_lons = population_count.lon\n",
    "grid_x_pop, grid_y_pop = np.meshgrid(pop_lons,pop_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "levels = range(1,1500000,20000)\n",
    "# levels = [1,1000,5000,10000,100000,120000,160000,180000,200000,400000,600000,800000,1000000,2000000,3000000,4000000,5000000]\n",
    "ax.contourf(lon,-lat + 12,data,levels=levels, transform=ccrs.PlateCarree(),cmap='Oranges')\n",
    "ax.add_feature(cfeature.COASTLINE,linewidth=0.5)\n",
    "ax.set_extent([-5, 5, 50, 60], crs=ccrs.PlateCarree())\t\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(data)\n",
    "print(np.min(data))\n",
    "data[data == -inf] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [10, 15, 20, 25, 30, 40, 50,75, 100,140,180,200,250,300]\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\")\n",
    "vmin=0\n",
    "vmax=300\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "ax.contourf(lon,-lat + 12,data,levels=range(1,200000,20000), transform=ccrs.PlateCarree(),cmap='Oranges')\n",
    "ax.contourf(grid_x,grid_y,np.sum(grid_rain_truth,axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "# ax.contourf(grid_x,grid_y,np.sum(grid_rain,axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "\n",
    "\n",
    "ax.add_feature(cfeature.COASTLINE,linewidth=0.5)\n",
    "ax.add_feature(cfeature.LAND, zorder=100,color='black',alpha=0.1)\n",
    "\n",
    "\n",
    "# plt.contourf(storm.precipitation[0,:,:,0],storm.storm_lats[0,:,:],storm.storm_lons[0,:,:])\n",
    "\n",
    "\n",
    "# ax.outline_patch.set_linewidth(0.5)\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "\t\t\tlinewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "gl.xlabel_style = {'size': 14}\n",
    "gl.ylabel_style = {'size': 14}\n",
    "# ax.set_xticklabels(labelsize=20)\n",
    "# ax.set_yticklabels(labelsize=20)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "precip_cmap,precip_norm = make_cmap(high_vals=True)\n",
    "# cbar = plt.colorbar(c,fraction=1.5, pad=-0.7,cmap=precip_cmap,ticks=levels,boundaries=levels, format='%1i',cax=ax)\n",
    "# cbar.ax.tick_params(labelsize=8,width=0.5)\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.set_extent([grid_x[0,0], grid_x[-1,-1], grid_y[0,0], grid_y[-1,-1]], crs=ccrs.PlateCarree())\n",
    "# ax.set_title('title',fontsize=26,pad=15)\n",
    "\n",
    "plt.savefig('figure_7a_irma_rain.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_x)\n",
    "print(grid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exposure\n",
    "# storm_pop = pop.sel(lat=slice(-lats[-1]+1+12,-lats[0]+12), lon=slice(lons[0],lons[-1]+1))\n",
    "# print(storm_pop)\n",
    "# storm_pop_data = storm_pop.population.values\n",
    "# print(storm_pop_data.shape)\n",
    "# print(np.sum(grid_rain,axis=0).shape)\n",
    "# print(grid_x.shape)\n",
    "print(pop.population.shape)\n",
    "accumulated_rain = np.sum(grid_rain[:,:,:,0],axis=0)\n",
    "accumulated_rain_truth = np.sum(grid_rain_truth,axis=0)\n",
    "\n",
    "\n",
    "# superimpose rain onto bigger grid\n",
    "global_rain = np.zeros((pop.population.shape[0],pop.population.shape[1]))\n",
    "global_rain_truth = np.zeros((pop.population.shape[0],pop.population.shape[1]))\n",
    "\n",
    "storm_lons = grid_x\n",
    "storm_lats = grid_y\n",
    "storm_rain = accumulated_rain\n",
    "storm_rain_truth = accumulated_rain_truth\n",
    "\n",
    "Mlon = storm_lons[-1,-1]\n",
    "mlon = storm_lons[0,0]\n",
    "Mlat = storm_lats[-1,-1]\n",
    "mlat = storm_lats[0,0]\n",
    "grid_X,grid_Y = np.meshgrid(lon,lat)\n",
    "Xspan = np.where((grid_X <= Mlon) & (grid_X >= mlon))[1][[0, -1]]\n",
    "Yspan = np.where((grid_Y <= Mlat) & (grid_Y >= mlat))[0][[0, -1]]\n",
    "\n",
    "# Create a selection\n",
    "sel = [slice(Xspan[0], Xspan[1] + 1), slice(Yspan[0], Yspan[1] + 1)]\n",
    "\n",
    "global_rain[sel[1],sel[0]] = storm_rain\n",
    "global_rain_truth[sel[1],sel[0]] = storm_rain_truth\n",
    "\n",
    "\n",
    "\n",
    "pred_exposure = exposure_calc(pop,global_rain,150)\n",
    "truth_exposure = exposure_calc(pop,global_rain_truth,150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_exposure)\n",
    "print(truth_exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(global_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ets(total_storm_rain,total_storm_rain_truth,pop,threshold=50):\n",
    "\n",
    "\train_bool = total_storm_rain > threshold\n",
    "\t# rain_grid_x = grid_X[rain_bool]\n",
    "\n",
    "\train_bool_truth = total_storm_rain_truth > threshold\n",
    "\t# rain_grid_x_truth = grid_X[rain_bool_truth]\n",
    "\n",
    "\thit = (rain_bool == True) & (rain_bool_truth == True)\n",
    "\tmiss = (rain_bool == False) & (rain_bool_truth == True)\n",
    "\thit_rate = np.sum(hit) / (np.sum(hit) + np.sum(miss))\n",
    "\tprint('Hit rate: ',hit_rate*100)\n",
    "\tpop_hit = np.sum(pop[hit])\n",
    "\tpop_miss = np.sum(pop[miss])\n",
    "\tpop_hit_rate = pop_hit / (pop_hit + pop_miss)\n",
    "\n",
    "\n",
    "\tfalse_alarm = (rain_bool == True) & (rain_bool_truth == False)\n",
    "\tcorrect_rejection = (rain_bool == False) & (rain_bool_truth == False)\n",
    "\tfalse_alarm_rate = np.sum(false_alarm)/(np.sum(false_alarm) + np.sum(correct_rejection))\n",
    "\tprint('false alarm rate',false_alarm_rate*100)\n",
    "\tpop_false_alarm = np.sum(pop[false_alarm])\n",
    "\tpop_correct_rejection = np.sum(pop[correct_rejection])\n",
    "\tpop_false_alarm_rate = pop_false_alarm / (pop_false_alarm + pop_correct_rejection)\n",
    "\n",
    "\t# equitable threat score is:\n",
    "\t# (hit - random chance) / (the observed rain area exceeding the criterion + model precticted area - hit - random chance)\n",
    "\t# where R = the observed rain area exceeding the criterion * (model predicted area / entire verification domain)\n",
    "\t# http://cimss.ssec.wisc.edu/goes/comet/threat.html\n",
    "\t# ETS = (hits - E) / (hits + misses + false alarms - E)\n",
    "\t# E = (number of forecast points * number of observed points) / total number of points possible\n",
    "\n",
    "\tn_forecast_points = np.sum(rain_bool == True)\n",
    "\tn_observed_points = np.sum(rain_bool_truth == True)\n",
    "\ttotal_points_possible = np.sum((rain_bool_truth == True) | (rain_bool_truth == False))\n",
    "\tE = (n_forecast_points*n_observed_points) / total_points_possible\n",
    "\tETS = (np.sum(hit) - E) / (np.sum(hit) + np.sum(miss) + np.sum(false_alarm) - E)\n",
    "\tprint('ETS: ', ETS)\n",
    "\n",
    "\tn_fp_pop = np.sum(pop[rain_bool])\n",
    "\tn_obs_pop = np.sum(pop[rain_bool_truth])\n",
    "\tbool = (rain_bool_truth == True) | (rain_bool_truth == False)\n",
    "\ttotal_pp_pop = np.sum(pop[bool])\n",
    "\tE_pop = (n_fp_pop*n_obs_pop) / total_pp_pop\n",
    "\tETS_pop = (np.sum(pop_hit) - E_pop) / (np.sum(pop_hit) + np.sum(pop_miss) + np.sum(pop_false_alarm) - E_pop)\n",
    "\tprint(ETS_pop)\n",
    "\n",
    "\treturn hit_rate,false_alarm_rate,ETS,pop_hit,pop_miss,pop_hit_rate,pop_false_alarm,pop_correct_rejection,pop_false_alarm_rate\n",
    "\t# The number of forecasts of the event correct by chance, a r , is determined by assuming that the forecasts are totally independent of the observations, and forecast will match the observation only by chance. This is one form of an unskilled forecast, which can be generated by just guessing what will happen. The ETS has a range of -1/3 to 1, but the minimum value depends on the verification sample climatology. For rare events, the minimum ETS value is near 0, while the absolute minimum is obtained if the event has a climatological frequency of 0.5, and there are no hits. If the score goes below 0 then the chance forecast is preferred to the actual forecast, and the forecast is said to be unskilled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pop)\n",
    "\n",
    "global_pop = pop.population.values\n",
    "\n",
    "global_pop[global_pop == -inf] = 0\n",
    "\n",
    "print(global_pop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate,false_alarm_rate,ETS,pop_hit,pop_miss,pop_hit_rate,pop_false_alarm,pop_correct_rejection,pop_false_alarm_rate = ets(global_rain,global_rain_truth,global_pop,threshold=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pop_hit_rate * 100)\n",
    "print(pop_false_alarm_rate * 100)\n",
    "print(grid_rain.shape)\n",
    "print(grid_rain_truth.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_steps,n,m,_ = grid_rain.shape\n",
    "combo_rain = np.zeros((n_time_steps,n,m))\n",
    "print(storm_scores.shape)\n",
    "for t in range(n_time_steps):\n",
    "\tt_scores = storm_scores[t,:]\n",
    "\tbest_score = np.argmax(t_scores)\n",
    "\tcombo_rain[t,:,:] = grid_rain[t,:,:,best_score]\n",
    "\n",
    "ensemble_combo = np.sum(combo_rain,axis=0)\n",
    "print(t_scores)\n",
    "print(ensemble_combo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels = [10, 15, 20, 25, 30, 40, 50,75, 100,140,180,200,250,300]\n",
    "# sns.set_style(\"white\")\n",
    "# sns.set_context(\"notebook\")\n",
    "# vmin=-2\n",
    "# vmax=2\n",
    "\n",
    "# TODO: add in combination of ensemble members. Not the mean, but based on the critic score of each image - e.g. the ones which are the best quality are the ones we select\n",
    "\n",
    "levels = [10, 15, 20, 25, 30, 40, 50,75, 100,140,180,200,250,300]\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\")\n",
    "vmin=0\n",
    "vmax=300\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(20,16),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "rain1 = np.sum(grid_rain[:,:,:,0],axis=0) > 50\n",
    "rain2 = np.sum(grid_rain_truth,axis=0) > 50\n",
    "hit = (rain1 == True) & (rain2 == True)\n",
    "miss = (rain1 == False) & (rain2 == True)\n",
    "false_alarm = (rain1 == True) & (rain2 == False)\n",
    "correct_rejection = (rain1 == False) & (rain2 == False)\n",
    "rain_data = hit + 2* miss + 3* false_alarm + 4*correct_rejection\n",
    "\n",
    "\n",
    "# Create a colormap with distinct colors\n",
    "colors = ['white', '#A3C9A9', '#C9A9A3', '#f2cc8f','white']\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Create color boundaries\n",
    "bounds = np.arange(1, 5, 1)\n",
    "\n",
    "# Create a BoundaryNorm instance\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n",
    "# norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# first panel\n",
    "axes[0,0].contourf(lon,-lat + 12,data,levels=range(1,200000,20000), transform=ccrs.PlateCarree(),cmap='Oranges')\n",
    "m = axes[0,0].contourf(grid_x,grid_y,np.sum(grid_rain_truth,axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "\n",
    "# second panel\n",
    "axes[1,0].contourf(lon,-lat + 12,data,levels=range(1,200000,20000), transform=ccrs.PlateCarree(),cmap='Oranges')\n",
    "\n",
    "agreement_range = 20\n",
    "ensemble_max = np.max(np.sum(grid_rain[:,:,:,:],axis=0),axis=-1)\n",
    "agree_mask = np.all([np.abs(np.sum(grid_rain[:,:,:,0],axis=0) - ensemble_max) <= agreement_range,\n",
    "                    np.abs(np.sum(grid_rain[:,:,:,1],axis=0) - ensemble_max) <= agreement_range,\n",
    "                    np.abs(np.sum(grid_rain[:,:,:,2],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain[:,:,:,3],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain[:,:,:,4],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain[:,:,:,5],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain[:,:,:,6],axis=0) - ensemble_max) <= agreement_range],\n",
    "\t\t\t\t\taxis=0)\n",
    "print(agree_mask)\n",
    "agree_mask = np.all([agree_mask,ensemble_max > 10],axis=0)\n",
    "axes[0,1].contourf(grid_x,grid_y,ensemble_combo,vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "axes[0,2].contourf(grid_x,grid_y,np.sum(grid_rain[:,:,:,0],axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "\n",
    "axes[1,0].contourf(grid_x,grid_y,ensemble_max,vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "axes[1,1].contourf(grid_x,grid_y,np.sum(grid_rain[:,:,:,0],axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "\n",
    "stand_dev = np.std(np.sum(grid_rain[:,:,:,:],axis=0),axis=-1)\n",
    "\n",
    "axes[1,1].contourf(grid_x,grid_y,stand_dev,vmin=0,vmax=40,levels=[0,5,10,15,20,30,40],cmap = 'Oranges', transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "# Create a hatching pattern\n",
    "hatching_pattern = ['/', '\\\\', '//', '\\\\\\\\', '-', '|', '+', 'x', 'o', 'O', '.', '*'][-1]\n",
    "# Add hatching to the areas of agreement\n",
    "# axes[1].contourf(grid_x, grid_y, 1* agree_mask,1,hatches=['','////'],colors='none',transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "h = axes[1,2].pcolormesh(grid_x,grid_y,rain_data,cmap=cmap, transform=ccrs.PlateCarree(), shading='auto', norm=norm)\n",
    "\n",
    "for i in range(3):\n",
    "\tfor j in range(2):\n",
    "\t\taxes[j,i].add_feature(cfeature.COASTLINE,linewidth=0.5)\n",
    "\t\taxes[j,i].add_feature(cfeature.LAND, zorder=100,color='black',alpha=0.1)\n",
    "\n",
    "\n",
    "\t\t# ax.outline_patch.set_linewidth(0.5)\n",
    "\t\tgl = axes[j,i].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "\t\t\t\t\tlinewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "\t\tgl.xlabels_top = False\n",
    "\t\tgl.ylabels_right = False\n",
    "\t\tgl.xlabel_style = {'size': 12}\n",
    "\t\tgl.ylabel_style = {'size': 12}\n",
    "\t\t# ax.set_xticklabels(labelsize=20)\n",
    "\t\t# ax.set_yticklabels(labelsize=20)\n",
    "\t\taxes[j,i].tick_params(axis='x', labelsize=14)\n",
    "\t\taxes[j,i].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "\t# precip_cmap,precip_norm = make_cmap(high_vals=True)\n",
    "\t# cbar = plt.colorbar(h, ticks=np.arange(0.5, 4.5, 1), boundaries=bounds, label='Rain Category')\n",
    "\t\taxes[j,i].set_extent([grid_x[0,0], grid_x[-1,-1], grid_y[0,0], grid_y[-1,-1]], crs=ccrs.PlateCarree())\n",
    "\t# ax.set_title('Hit and Miss',fontsize=18,pad=15)\n",
    "\n",
    "axes[0,0].text(-0.1, 1.05, 'a.', transform=axes[0,0].transAxes, size=18, weight='bold')\n",
    "axes[0,1].text(-0.1, 1.05, 'b.', transform=axes[0,1].transAxes, size=18, weight='bold')\n",
    "axes[0,2].text(-0.1, 1.05, 'c.', transform=axes[0,2].transAxes, size=18, weight='bold')\n",
    "axes[1,0].text(-0.1, 1.05, 'd.', transform=axes[1,0].transAxes, size=18, weight='bold')\n",
    "axes[1,1].text(-0.1, 1.05, 'e.', transform=axes[1,1].transAxes, size=18, weight='bold')\n",
    "axes[1,2].text(-0.1, 1.05, 'f.', transform=axes[1,2].transAxes, size=18, weight='bold')\n",
    "legend_labels = ['LEGEND', 'Hit', 'Miss', 'False alarm','Correct rejection']\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, markerfacecolor=color, markersize=10) for color, label in zip(colors, legend_labels)]\n",
    "axes[1,2].legend(handles=legend_handles, loc='upper right')\n",
    "\n",
    "axes[0,0].set_title('Truth',fontsize=18,pad=10)\n",
    "axes[0,1].set_title('Predicted (critic combined ensemble)',fontsize=18,pad=10)\n",
    "axes[0,2].set_title('Predicted (first ensemble member)',fontsize=18,pad=10)\n",
    "axes[1,0].set_title('Predicted (ensemble max)',fontsize=18,pad=10)\n",
    "axes[1,1].set_title('Standard deviation',fontsize=18,pad=10)\n",
    "axes[1,2].set_title('Hit and Miss',fontsize=18,pad=10)\n",
    "\n",
    "# cbar = plt.colorbar(m,fraction=1.5, pad=-0.7,cmap=precip_cmap,ticks=levels,boundaries=levels, format='%1i',cax=axes[0])\n",
    "# cbar.ax.tick_params(labelsize=8,width=0.5)\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "# cbar = plt.colorbar(m,fraction=1.5, pad=-0.7,cmap=precip_cmap,ticks=levels,boundaries=levels, format='%1i',cax=axes[1])\n",
    "# cbar.ax.tick_params(labelsize=8,width=0.5)\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "plt.savefig('figure_7b_hitmiss.png',bbox_inches='tight')\n",
    "\n",
    "# TODO: compare hit miss and ets of combined score vs max and first,second,third etc\n",
    "\n",
    "# TODO: rainfall is gamma distribution so std not that meaningful, so plot most probable rainfall (not mean) up to 95th percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# the question is, what level of extreme rainfall can we be confident in calculating the exposure to?\n",
    "# how often are we wrong when it's 50mm,100mm,150mm\n",
    "# how often are we right?\n",
    "# do the ensemble combining method with critic score so best of 20 images are selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels = [10, 15, 20, 25, 30, 40, 50,75, 100,140,180,200,250,300]\n",
    "# sns.set_style(\"white\")\n",
    "# sns.set_context(\"notebook\")\n",
    "# vmin=-2\n",
    "# vmax=2\n",
    "\n",
    "# TODO: add in combination of ensemble members. Not the mean, but based on the critic score of each image - e.g. the ones which are the best quality are the ones we select\n",
    "\n",
    "levels = [10, 15, 20, 25, 30, 40, 50,75, 100,140,180,200,250,300]\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\")\n",
    "vmin=0\n",
    "vmax=300\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(20,16),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "rain1 = np.sum(grid_rain2[:,:,:,0],axis=0) > 50\n",
    "rain2 = np.sum(grid_rain_truth,axis=0) > 50\n",
    "hit = (rain1 == True) & (rain2 == True)\n",
    "miss = (rain1 == False) & (rain2 == True)\n",
    "false_alarm = (rain1 == True) & (rain2 == False)\n",
    "correct_rejection = (rain1 == False) & (rain2 == False)\n",
    "rain_data = hit + 2* miss + 3* false_alarm + 4*correct_rejection\n",
    "\n",
    "\n",
    "# Create a colormap with distinct colors\n",
    "colors = ['white', '#A3C9A9', '#C9A9A3', '#f2cc8f','white']\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Create color boundaries\n",
    "bounds = np.arange(1, 5, 1)\n",
    "\n",
    "# Create a BoundaryNorm instance\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N, extend='both')\n",
    "# norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# first panel\n",
    "axes[0,0].contourf(lon,-lat + 12,data,levels=range(1,200000,20000), transform=ccrs.PlateCarree(),cmap='Oranges')\n",
    "m = axes[0,0].contourf(grid_x,grid_y,np.sum(grid_rain_truth,axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "\n",
    "# second panel\n",
    "axes[1,0].contourf(lon,-lat + 12,data,levels=range(1,200000,20000), transform=ccrs.PlateCarree(),cmap='Oranges')\n",
    "\n",
    "agreement_range = 20\n",
    "ensemble_max = np.max(np.sum(grid_rain2[:,:,:,:],axis=0),axis=-1)\n",
    "agree_mask = np.all([np.abs(np.sum(grid_rain2[:,:,:,0],axis=0) - ensemble_max) <= agreement_range,\n",
    "                    np.abs(np.sum(grid_rain2[:,:,:,1],axis=0) - ensemble_max) <= agreement_range,\n",
    "                    np.abs(np.sum(grid_rain2[:,:,:,2],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain2[:,:,:,3],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain2[:,:,:,4],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain2[:,:,:,5],axis=0) - ensemble_max) <= agreement_range,\n",
    "\t\t\t\t\tnp.abs(np.sum(grid_rain2[:,:,:,6],axis=0) - ensemble_max) <= agreement_range],\n",
    "\t\t\t\t\taxis=0)\n",
    "print(agree_mask)\n",
    "agree_mask = np.all([agree_mask,ensemble_max > 10],axis=0)\n",
    "axes[0,1].contourf(grid_x,grid_y,ensemble_combo,vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "axes[0,2].contourf(grid_x,grid_y,np.sum(grid_rain2[:,:,:,0],axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "\n",
    "axes[1,0].contourf(grid_x,grid_y,ensemble_max,vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "axes[1,1].contourf(grid_x,grid_y,np.sum(grid_rain2[:,:,:,0],axis=0),vmin=vmin,vmax=vmax,levels=levels,cmap = precip_cmap, transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "\n",
    "stand_dev = np.std(np.sum(grid_rain2[:,:,:,:],axis=0),axis=-1)\n",
    "\n",
    "axes[1,1].contourf(grid_x,grid_y,stand_dev,vmin=0,vmax=40,levels=[0,5,10,15,20,30,40],cmap = 'Oranges', transform=ccrs.PlateCarree(),alpha=0.8)\n",
    "# Create a hatching pattern\n",
    "hatching_pattern = ['/', '\\\\', '//', '\\\\\\\\', '-', '|', '+', 'x', 'o', 'O', '.', '*'][-1]\n",
    "# Add hatching to the areas of agreement\n",
    "# axes[1].contourf(grid_x, grid_y, 1* agree_mask,1,hatches=['','////'],colors='none',transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "h = axes[1,2].pcolormesh(grid_x,grid_y,rain_data,cmap=cmap, transform=ccrs.PlateCarree(), shading='auto', norm=norm)\n",
    "\n",
    "for i in range(3):\n",
    "\tfor j in range(2):\n",
    "\t\taxes[j,i].add_feature(cfeature.COASTLINE,linewidth=0.5)\n",
    "\t\taxes[j,i].add_feature(cfeature.LAND, zorder=100,color='black',alpha=0.1)\n",
    "\n",
    "\n",
    "\t\t# ax.outline_patch.set_linewidth(0.5)\n",
    "\t\tgl = axes[j,i].gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "\t\t\t\t\tlinewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "\t\tgl.xlabels_top = False\n",
    "\t\tgl.ylabels_right = False\n",
    "\t\tgl.xlabel_style = {'size': 12}\n",
    "\t\tgl.ylabel_style = {'size': 12}\n",
    "\t\t# ax.set_xticklabels(labelsize=20)\n",
    "\t\t# ax.set_yticklabels(labelsize=20)\n",
    "\t\taxes[j,i].tick_params(axis='x', labelsize=14)\n",
    "\t\taxes[j,i].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "\t# precip_cmap,precip_norm = make_cmap(high_vals=True)\n",
    "\t# cbar = plt.colorbar(h, ticks=np.arange(0.5, 4.5, 1), boundaries=bounds, label='Rain Category')\n",
    "\t\taxes[j,i].set_extent([grid_x[0,0], grid_x[-1,-1], grid_y[0,0], grid_y[-1,-1]], crs=ccrs.PlateCarree())\n",
    "\t# ax.set_title('Hit and Miss',fontsize=18,pad=15)\n",
    "\n",
    "axes[0,0].text(-0.1, 1.05, 'a.', transform=axes[0,0].transAxes, size=18, weight='bold')\n",
    "axes[0,1].text(-0.1, 1.05, 'b.', transform=axes[0,1].transAxes, size=18, weight='bold')\n",
    "axes[0,2].text(-0.1, 1.05, 'c.', transform=axes[0,2].transAxes, size=18, weight='bold')\n",
    "axes[1,0].text(-0.1, 1.05, 'd.', transform=axes[1,0].transAxes, size=18, weight='bold')\n",
    "axes[1,1].text(-0.1, 1.05, 'e.', transform=axes[1,1].transAxes, size=18, weight='bold')\n",
    "axes[1,2].text(-0.1, 1.05, 'f.', transform=axes[1,2].transAxes, size=18, weight='bold')\n",
    "legend_labels = ['LEGEND', 'Hit', 'Miss', 'False alarm','Correct rejection']\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, markerfacecolor=color, markersize=10) for color, label in zip(colors, legend_labels)]\n",
    "axes[1,2].legend(handles=legend_handles, loc='upper right')\n",
    "\n",
    "axes[0,0].set_title('Truth',fontsize=18,pad=10)\n",
    "axes[0,1].set_title('Predicted (critic combined ensemble)',fontsize=18,pad=10)\n",
    "axes[0,2].set_title('Predicted (first ensemble member)',fontsize=18,pad=10)\n",
    "axes[1,0].set_title('Predicted (ensemble max)',fontsize=18,pad=10)\n",
    "axes[1,1].set_title('Standard deviation',fontsize=18,pad=10)\n",
    "axes[1,2].set_title('Hit and Miss (<50 mm)',fontsize=18,pad=10)\n",
    "\n",
    "# cbar = plt.colorbar(m,fraction=1.5, pad=-0.7,cmap=precip_cmap,ticks=levels,boundaries=levels, format='%1i',cax=axes[0])\n",
    "# cbar.ax.tick_params(labelsize=8,width=0.5)\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "# cbar = plt.colorbar(m,fraction=1.5, pad=-0.7,cmap=precip_cmap,ticks=levels,boundaries=levels, format='%1i',cax=axes[1])\n",
    "# cbar.ax.tick_params(labelsize=8,width=0.5)\n",
    "# cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "plt.savefig('figure_7c_hitmiss_2.png',bbox_inches='tight')\n",
    "\n",
    "# TODO: compare hit miss and ets of combined score vs max and first,second,third etc\n",
    "\n",
    "# TODO: rainfall is gamma distribution so std not that meaningful, so plot most probable rainfall (not mean) up to 95th percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jungle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
